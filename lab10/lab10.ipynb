{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright **`(c)`** 2023 Giovanni Squillero `<giovanni.squillero@polito.it>`  \n",
    "[`https://github.com/squillero/computational-intelligence`](https://github.com/squillero/computational-intelligence)  \n",
    "Free for personal or classroom use; see [`LICENSE.md`](https://github.com/squillero/computational-intelligence/blob/master/LICENSE.md) for details.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB10\n",
    "\n",
    "Use reinforcement learning to devise a tic-tac-toe player.\n",
    "\n",
    "### Deadlines:\n",
    "\n",
    "* Submission: [Dies Natalis Solis Invicti](https://en.wikipedia.org/wiki/Sol_Invictus)\n",
    "* Reviews: [Befana](https://en.wikipedia.org/wiki/Befana)\n",
    "\n",
    "Notes:\n",
    "\n",
    "* Reviews will be assigned  on Monday, December 4\n",
    "* You need to commit in order to be selected as a reviewer (ie. better to commit an empty work than not to commit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "from collections import namedtuple, defaultdict\n",
    "from random import choice, random\n",
    "from copy import deepcopy\n",
    "import json\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "State = namedtuple('State', ['x', 'o'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAGIC = [2, 7, 6, 9, 5, 1, 4, 3, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Color:\n",
    "    RESET = '\\033[0m'\n",
    "    RED = '\\033[91m'\n",
    "    GREEN = '\\033[92m'\n",
    "    YELLOW = '\\033[93m'\n",
    "    BLUE = '\\033[94m'\n",
    "    PURPLE = '\\033[95m'\n",
    "    CYAN = '\\033[96m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_board(pos):\n",
    "    \"\"\"Nicely prints the board\"\"\"\n",
    "    for r in range(3):\n",
    "        for c in range(3):\n",
    "            i = r * 3 + c\n",
    "            if MAGIC[i] in pos.x:\n",
    "                print('X', end='')\n",
    "            elif MAGIC[i] in pos.o:\n",
    "                print('O', end='')\n",
    "            else:\n",
    "                print('.', end='')\n",
    "        print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "def win(elements):\n",
    "    \"\"\"Checks is elements is winning\"\"\"\n",
    "    return any(sum(c) == 15 for c in combinations(elements, 3))\n",
    "\n",
    "def state_value(pos: State):\n",
    "    \"\"\"Evaluate state: +1 first player wins\"\"\"\n",
    "    if win(pos.x):\n",
    "        return 1\n",
    "    elif win(pos.o):\n",
    "        return -1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_game():\n",
    "    trajectory = list()\n",
    "    state = State(set(), set())\n",
    "    available = set(range(1, 9+1))\n",
    "    while available:\n",
    "        x = choice(list(available))\n",
    "        state.x.add(x)\n",
    "        trajectory.append(deepcopy(state))\n",
    "        available.remove(x)\n",
    "        if win(state.x) or not available:\n",
    "            break\n",
    "\n",
    "        o = choice(list(available))\n",
    "        state.o.add(o)\n",
    "        trajectory.append(deepcopy(state))\n",
    "        available.remove(o)\n",
    "        if win(state.o):\n",
    "            break\n",
    "    return trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'value_dictionary = defaultdict(float)\\nhit_state = defaultdict(int)\\nepsilon = 0.001\\n\\nfor steps in tqdm(range(500_000)):\\n    trajectory = random_game()\\n    final_reward = state_value(trajectory[-1])\\n    for state in trajectory:\\n        hashable_state = (frozenset(state.x), frozenset(state.o))\\n        hit_state[hashable_state] += 1\\n        value_dictionary[hashable_state] = value_dictionary[\\n            hashable_state\\n        ] + epsilon * (final_reward - value_dictionary[hashable_state])'"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"value_dictionary = defaultdict(float)\n",
    "hit_state = defaultdict(int)\n",
    "epsilon = 0.001\n",
    "\n",
    "for steps in tqdm(range(500_000)):\n",
    "    trajectory = random_game()\n",
    "    final_reward = state_value(trajectory[-1])\n",
    "    for state in trajectory:\n",
    "        hashable_state = (frozenset(state.x), frozenset(state.o))\n",
    "        hit_state[hashable_state] += 1\n",
    "        value_dictionary[hashable_state] = value_dictionary[\n",
    "            hashable_state\n",
    "        ] + epsilon * (final_reward - value_dictionary[hashable_state])\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.1\n",
    "gamma = 0.98\n",
    "fixed_epsilon = 0.2\n",
    "# fixed_epsilon = 0.      # when optimistic initial values\n",
    "# epsilon = fixed_epsilon\n",
    "# GLIE approach\n",
    "episodes = 200_000\n",
    "k = episodes\n",
    "eps_k = 0.1\n",
    "b = (eps_k * k) // (1 - eps_k)\n",
    "\n",
    "\n",
    "class agent:\n",
    "  def __init__(self):\n",
    "    # zero initialization\n",
    "    self.q_table = defaultdict(lambda: np.zeros(9, dtype=float))\n",
    "    # optimistic initial value\n",
    "    # self.q_table = defaultdict(lambda: np.full(9, 50, dtype=float))\n",
    "  \n",
    "  def get_action(self, state, available_actions, epsilon=fixed_epsilon):\n",
    "    '''print(\"Get : \")\n",
    "    print(f\"Epsilon : {epsilon}\")'''\n",
    "    if np.random.rand() < epsilon:\n",
    "      action =  choice(available_actions)\n",
    "      '''print(f\"{Color.YELLOW}rand action: {action+1}{Color.RESET}\")'''\n",
    "      return action\n",
    "    else:\n",
    "      hashable_state = (frozenset(state.x), frozenset(state.o))\n",
    "      '''print(f\"cumulative exp rew :\\t{self.q_table[hashable_state][available_actions]}\")'''\n",
    "      best_action_index = np.argmax(self.q_table[hashable_state][available_actions])\n",
    "      best_action_value = self.q_table[hashable_state][available_actions][best_action_index]\n",
    "      best_action = list(available_actions)[best_action_index]\n",
    "      '''print(f\"{Color.GREEN}best action val:{best_action_value},\\tbest action: {best_action+1}{Color.RESET}\")'''\n",
    "      return best_action\n",
    "  \n",
    "  def update(self, state, action, reward, next_state, done):\n",
    "    # print(f\"action : {action}\")\n",
    "    '''print(\"Update : \")'''\n",
    "    if done:\n",
    "      target_value = reward\n",
    "    else:\n",
    "      hashable_next_state = (frozenset(next_state.x), frozenset(next_state.o))\n",
    "      #print(f\"max : {np.max(gamma * self.q_table[hashable_next_state])}\")\n",
    "      target_value = reward + np.max(gamma * self.q_table[hashable_next_state])\n",
    "    \n",
    "    '''print(f\"t: {target_value}\")'''\n",
    "    \n",
    "    hashable_state = (frozenset(state.x), frozenset(state.o))\n",
    "    self.q_table[hashable_state][action] += (alpha * (target_value - self.q_table[hashable_state][action]))\n",
    "    '''print(f\"values : {self.q_table[hashable_state]}, value: {self.q_table[hashable_state][action]}\")'''\n",
    "    return\n",
    "    \n",
    "  def play(self, state, available_actions):\n",
    "    hashable_state = (frozenset(state.x), frozenset(state.o))\n",
    "    # print(f\"cumulative exp rew :\\t{self.q_table[hashable_state][available_actions]}\")\n",
    "    best_action_index = np.argmax(self.q_table[hashable_state][available_actions])\n",
    "    best_action_value = self.q_table[hashable_state][available_actions][best_action_index]\n",
    "    best_action = list(available_actions)[best_action_index]\n",
    "    # print(f\"{Color.GREEN}best action val:{best_action_value},\\tbest action: {best_action+1}{Color.RESET}\")\n",
    "    available_actions.remove(best_action)\n",
    "    return best_action, available_actions\n",
    "  \n",
    "  def save_q_table(self, filename):\n",
    "    q_table_dict = {str(key): value.tolist() for key, value in self.q_table.items()}\n",
    "    with open(filename, 'w') as file:\n",
    "      json.dump(q_table_dict, file)\n",
    "\n",
    "  def load_q_table(self, filename):\n",
    "    with open(filename, 'r') as file:\n",
    "      q_table_dict = json.load(file)\n",
    "\n",
    "    self.q_table = defaultdict(lambda: np.zeros(9, dtype=float))\n",
    "    for key, value in q_table_dict.items():\n",
    "      for i in range(9):\n",
    "        self.q_table[eval(key)] = np.array(value)\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_action(action, available_actions, state, turn):\n",
    "    done = False\n",
    "    if turn == 0:\n",
    "      state.o.add(action+1)\n",
    "    else:\n",
    "      state.x.add(action+1)\n",
    "    available_actions.remove(action)\n",
    "    if len(available_actions) == 0: done = True\n",
    "    return state, done\n",
    "\n",
    "target_vector = [2, 4, 6, 8]\n",
    "\n",
    "def get_reward(state, done, available_actions, turn=1):\n",
    "    if win(state.o):\n",
    "      '''print(\"win: o\")'''\n",
    "      return -100, True\n",
    "    reward = 0\n",
    "    count_combinations = 0\n",
    "\n",
    "    if turn == 1:\n",
    "      # if there is an action for o to win and x did not block it => reward -= 1\n",
    "      # o will perform it the next turn !\n",
    "      elements = list(state.o)\n",
    "      for act in available_actions:\n",
    "        elements.append(act+1)\n",
    "        if any(sum(c) == 15 for c in combinations(elements, 3)):\n",
    "          reward -= 3\n",
    "        elements.remove(act+1)\n",
    "\n",
    "    # if the action of x is blocking the winning of o => reward += 1\n",
    "    # if no action is blocking the winning of o => reward = -10\n",
    "    for x in state.x:\n",
    "      elements = list(state.o)\n",
    "      elements.append(x)\n",
    "      count_combinations += sum(1 for c in combinations(elements, 3) if sum(c) == 15)\n",
    "      elements.remove(x)\n",
    "    reward += count_combinations\n",
    "    # if x sets 3 elements at the corner (config that facilitates the win)\n",
    "    reward += sum(1 for c in combinations(state.x, 3) if c in target_vector)\n",
    "        \n",
    "    if win(state.x):\n",
    "      '''print(\"win: x\")'''\n",
    "      reward += 50\n",
    "      return reward, True\n",
    "    else:\n",
    "      return reward, done\n",
    "    \n",
    "def my_player(state, available_actions, flag):\n",
    "   # random player\n",
    "  action = choice(available_actions)\n",
    "  # win if you can\n",
    "  if len(state.o) >= 2 and not any(sum(c) == 15 for c in combinations(state.o, 3)):\n",
    "    elements = list(state.o)\n",
    "    '''print(elements)'''\n",
    "    for act in available_actions:\n",
    "      elements.append(act+1)\n",
    "      '''print(elements)'''\n",
    "      if any(sum(c) == 15 for c in combinations(elements, 3)):\n",
    "        action = act\n",
    "        '''print(act+1)'''\n",
    "        flag = 1\n",
    "        return action, flag\n",
    "      elements.remove(act+1)\n",
    "  # if you can block the winning do it\n",
    "  for act in available_actions:\n",
    "    elements = list(state.x)\n",
    "    elements.append(act+1)\n",
    "    if win(elements):  # if the action make x win => prevent it\n",
    "      action = act\n",
    "      '''print_board(state)\n",
    "      print(act+1)'''\n",
    "      return action, flag\n",
    "    elements.remove(act+1)\n",
    "      \n",
    "  return action, flag\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccb9e0c8b2ec4dd1b4f8c06707c0145c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# epsilon = fixed_epsilon\n",
    "a = agent()\n",
    "hist  = np.zeros(10)\n",
    "for i in tqdm(range(10)):\n",
    "  state = State(set(), set())\n",
    "  done = False\n",
    "  available_actions = list(range(9))\n",
    "  turn = 1\n",
    "  #turn = np.random.choice([0,1])\n",
    "  '''print(f\"starts: {'o' if turn == 0 else 'x'}\")'''\n",
    "  state = State(set(), set())\n",
    "  done = False\n",
    "  available_actions = list(range(9))\n",
    "  epsilon = 0\n",
    "  while not done:\n",
    "    action = a.get_action(state, available_actions, epsilon)\n",
    "    # print(f\"actual s: {state}\")\n",
    "    next_state, done = perform_action(action, available_actions, deepcopy(state), turn)\n",
    "    # print(f\"turn: {'o' if turn == 0 else 'x'}\")\n",
    "    # print(f\"action: {action+1}\")\n",
    "    # print(f\"s:{state}, ns:{next_state}\")\n",
    "    '''print_board(state)\n",
    "    print_board(next_state)'''\n",
    "    turn = 1- turn\n",
    "    # print(f\"next s: {next_state}\")\n",
    "    reward, done = get_reward(next_state, done, available_actions)\n",
    "    a.update(state, action, reward, next_state, done)\n",
    "    state = next_state\n",
    "    '''print(\"----------------------------------------------\")'''\n",
    "    if reward == 1: hist[i] = 1\n",
    "    #if done:  print_board(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'print_board(state)\\nprint(act)'"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = agent()\n",
    "state = State(set(), set())\n",
    "done = False\n",
    "available_actions = list(range(9))\n",
    "turn = 1\n",
    "act = list()\n",
    "while not done:\n",
    "  action = a.get_action(state, available_actions)\n",
    "  '''print(f\"actual s: {state}\")'''\n",
    "  next_state, done = perform_action(action, available_actions, deepcopy(state), turn)\n",
    "  act.append(action+1)\n",
    "  '''print(f\"turn: {'o' if turn == 0 else 'x'}\")\n",
    "  print(f\"action: {action+1}\")\n",
    "  print_board(state)\n",
    "  print_board(next_state)'''\n",
    "  turn = 1- turn\n",
    "  '''print(f\"next s: {next_state}\")'''\n",
    "  reward, done = get_reward(next_state, done, available_actions)\n",
    "  '''if done: print(\"done\")'''\n",
    "  a.update(state, action, reward, next_state, done)\n",
    "  state = next_state\n",
    "\n",
    "'''print_board(state)\n",
    "print(act)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c8b7604c7b440e2841d5bc1a5643207",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# epsilon = fixed_epsilon\n",
    "saves = 0\n",
    "a = agent()\n",
    "hist  = np.zeros(episodes)\n",
    "for i in tqdm(range(episodes)):\n",
    "  state = State(set(), set())\n",
    "  done = False\n",
    "  available_actions = list(range(9))\n",
    "  #turn = 1\n",
    "  turn = np.random.choice([0,1])\n",
    "  '''print(f\"starts: {'o' if turn == 0 else 'x'}\")'''\n",
    "  state = State(set(), set())\n",
    "  done = False\n",
    "  available_actions = list(range(9))\n",
    "  epsilon = b / (b + i)\n",
    "  while not done:\n",
    "    flag = 0\n",
    "    if turn == 1:\n",
    "      # epsilon greedy player\n",
    "      action = a.get_action(state, available_actions, epsilon)\n",
    "      # fixed eps\n",
    "      # action = a.get_action(state, available_actions)\n",
    "    else:\n",
    "      action, flag = my_player(state, available_actions, flag)\n",
    "    # print(f\"actual s: {state}\")\n",
    "    next_state, done = perform_action(action, available_actions, deepcopy(state), turn)\n",
    "    '''if flag==1:\n",
    "      print_board(next_state)'''\n",
    "    # print(f\"turn: {'o' if turn == 0 else 'x'}\")\n",
    "    # print(f\"action: {action+1}\")\n",
    "    # print(f\"s:{state}, ns:{next_state}\")\n",
    "    # print_board(state)\n",
    "    # print_board(next_state)\n",
    "    # print(f\"next s: {next_state}\")\n",
    "    reward, done = get_reward(next_state, done, available_actions, turn)\n",
    "    '''if flag == 1 and done: print(\"vinto o scelta\")'''\n",
    "    a.update(state, action, reward, next_state, done)\n",
    "    state = next_state\n",
    "    if reward == 1: hist[i] = 1\n",
    "    turn = 1- turn\n",
    "    #if done:  print_board(state)\n",
    "\n",
    "a.save_q_table(f\"q_table_{episodes}_({saves}).json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c14e542860e74471a82509040baa481c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b59c4ae050174361b9907ca1e87985d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cbcff6e57bd44c99f4c9cfa3aa4aa80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10743befcb2b46a1bb41ab1cf2916cb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1809948516a94a57a67cc49eabc0dea7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# epsilon = fixed_epsilon\n",
    "for saves in range(5):\n",
    "  a = agent()\n",
    "  hist  = np.zeros(episodes)\n",
    "  for i in tqdm(range(episodes)):\n",
    "    state = State(set(), set())\n",
    "    done = False\n",
    "    available_actions = list(range(9))\n",
    "    #turn = 1\n",
    "    turn = np.random.choice([0,1])\n",
    "    '''print(f\"starts: {'o' if turn == 0 else 'x'}\")'''\n",
    "    state = State(set(), set())\n",
    "    done = False\n",
    "    available_actions = list(range(9))\n",
    "    epsilon = b / (b + i)\n",
    "    while not done:\n",
    "      flag = 0\n",
    "      if turn == 1:\n",
    "        # epsilon greedy player\n",
    "        action = a.get_action(state, available_actions, epsilon)\n",
    "        # fixed eps\n",
    "        # action = a.get_action(state, available_actions)\n",
    "      else:\n",
    "        action, flag = my_player(state, available_actions, flag)\n",
    "      # print(f\"actual s: {state}\")\n",
    "      next_state, done = perform_action(action, available_actions, deepcopy(state), turn)\n",
    "      '''if flag==1:\n",
    "        print_board(next_state)'''\n",
    "      # print(f\"turn: {'o' if turn == 0 else 'x'}\")\n",
    "      # print(f\"action: {action+1}\")\n",
    "      # print(f\"s:{state}, ns:{next_state}\")\n",
    "      # print_board(state)\n",
    "      # print_board(next_state)\n",
    "      # print(f\"next s: {next_state}\")\n",
    "      reward, done = get_reward(next_state, done, available_actions, turn)\n",
    "      '''if flag == 1 and done: print(\"vinto o scelta\")'''\n",
    "      a.update(state, action, reward, next_state, done)\n",
    "      state = next_state\n",
    "      if reward == 1: hist[i] = 1\n",
    "      turn = 1- turn\n",
    "      #if done:  print_board(state)\n",
    "  \n",
    "  a.save_q_table(f\"q_table_{episodes}_({saves}).json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.save_q_table(f\"q_table_{episodes}_episodes.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.load_q_table(\"q_table_200_000_(0).json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "win rate: 0.539\n",
      "draw rate: 0.148\n",
      "losts : 0.31299999999999994\n"
     ]
    }
   ],
   "source": [
    "\n",
    "wins = 0\n",
    "draws = 0\n",
    "test = 1000\n",
    "for _ in range(test):\n",
    "    state = State(set(), set())\n",
    "    available = list(range(9))\n",
    "    # print(f\"{[i+1 for i in available]}\")\n",
    "    trajectory = list()\n",
    "    turn = np.random.choice([0,1])\n",
    "    while available:\n",
    "        if turn == 1 :\n",
    "            x, available = a.play(state, available)\n",
    "            # print(f\"{[i+1 for i in available]} {x+1}\")\n",
    "            state.x.add(x+1)\n",
    "            trajectory.append(deepcopy(state))\n",
    "            if win(state.x):\n",
    "                wins += 1\n",
    "                #print(\"x wins\")\n",
    "                break\n",
    "            if not available:\n",
    "                draws += 1\n",
    "                #print(\"draw\")\n",
    "                break\n",
    "        else:\n",
    "            # o = choice(available)\n",
    "            o, _ = my_player(state, available, 0)\n",
    "            state.o.add(o+1)\n",
    "            trajectory.append(deepcopy(state))\n",
    "            available.remove(o)\n",
    "            # print(f\"{[i+1 for i in available]} {o+1}\")\n",
    "            if win(state.o):\n",
    "                #print(\"o wins\")\n",
    "                '''for t in trajectory:\n",
    "                    print_board(t)'''\n",
    "                break\n",
    "            if not available:\n",
    "                draws += 1\n",
    "                #print(\"draw\")\n",
    "                break\n",
    "        turn = 1 - turn\n",
    "    '''for t in trajectory:\n",
    "        print_board(t)'''\n",
    "    #print_board(state)\n",
    "print(f\"win rate: {wins/test}\")\n",
    "print(f\"draw rate: {draws/test}\")\n",
    "print(f\"losts : {1 - (wins + draws)/test}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "win rate: 0.612\n",
      "draw rate: 0.164\n",
      "losts : 0.22399999999999998\n"
     ]
    }
   ],
   "source": [
    "wins = 0\n",
    "draws = 0\n",
    "test = 1000\n",
    "for _ in range(test):\n",
    "    state = State(set(), set())\n",
    "    available = list(range(9))\n",
    "    # print(f\"{[i+1 for i in available]}\")\n",
    "    trajectory = list()\n",
    "    turn = np.random.choice([0,1])\n",
    "    while available:\n",
    "        if turn == 1 :\n",
    "            x, available = a.play(state, available)\n",
    "            # print(f\"{[i+1 for i in available]} {x+1}\")\n",
    "            state.x.add(x+1)\n",
    "            trajectory.append(deepcopy(state))\n",
    "            if win(state.x):\n",
    "                wins += 1\n",
    "                # print(\"x wins\")\n",
    "                break\n",
    "            if not available:\n",
    "                draws += 1\n",
    "                # print(\"draw\")\n",
    "                break\n",
    "        else:\n",
    "            o = choice(available)\n",
    "            #o, _ = my_player(state, available, 0)\n",
    "            state.o.add(o+1)\n",
    "            trajectory.append(deepcopy(state))\n",
    "            available.remove(o)\n",
    "            # print(f\"{[i+1 for i in available]} {o+1}\")\n",
    "            if win(state.o):\n",
    "                '''print(\"o wins\")\n",
    "                for t in trajectory:\n",
    "                    print_board(t)'''\n",
    "                break\n",
    "            if not available:\n",
    "                draws += 1\n",
    "                '''print(\"draw\")'''\n",
    "                break\n",
    "        turn = 1 - turn\n",
    "    #print_board(state)\n",
    "print(f\"win rate: {wins/test}\")\n",
    "print(f\"draw rate: {draws/test}\")\n",
    "print(f\"losts : {1 - (wins + draws)/test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "win rate: 0.485\n",
      "draw rate: 0.17\n",
      "losts : 0.345\n"
     ]
    }
   ],
   "source": [
    "for x in range(1):\n",
    "  a.load_q_table(f\"q_table_200000_({x})_r2.json\")\n",
    "  wins = 0\n",
    "  draws = 0\n",
    "  test = 1000\n",
    "  for _ in range(test):\n",
    "      state = State(set(), set())\n",
    "      available = list(range(9))\n",
    "      # print(f\"{[i+1 for i in available]}\")\n",
    "      trajectory = list()\n",
    "      turn = np.random.choice([0,1])\n",
    "      while available:\n",
    "          if turn == 1 :\n",
    "              x, available = a.play(state, available)\n",
    "              # print(f\"{[i+1 for i in available]} {x+1}\")\n",
    "              state.x.add(x+1)\n",
    "              trajectory.append(deepcopy(state))\n",
    "              if win(state.x):\n",
    "                  wins += 1\n",
    "                  # print(\"x wins\")\n",
    "                  break\n",
    "              if not available:\n",
    "                  draws += 1\n",
    "                  # print(\"draw\")\n",
    "                  break\n",
    "          else:\n",
    "              o = choice(available)\n",
    "              #o, _ = my_player(state, available, 0)\n",
    "              state.o.add(o+1)\n",
    "              trajectory.append(deepcopy(state))\n",
    "              available.remove(o)\n",
    "              # print(f\"{[i+1 for i in available]} {o+1}\")\n",
    "              if win(state.o):\n",
    "                  '''print(\"o wins\")\n",
    "                  for t in trajectory:\n",
    "                      print_board(t)'''\n",
    "                  break\n",
    "              if not available:\n",
    "                  draws += 1\n",
    "                  '''print(\"draw\")'''\n",
    "                  break\n",
    "          turn = 1 - turn\n",
    "      #print_board(state)\n",
    "  print(f\"win rate: {wins/test}\")\n",
    "  print(f\"draw rate: {draws/test}\")\n",
    "  print(f\"losts : {1 - (wins + draws)/test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(14, 4))\n",
    "k = 10\n",
    "plt.bar(range(0, len(hist), k), hist[::k], color='skyblue')\n",
    "\n",
    "plt.xlabel('Episodes')\n",
    "plt.ylabel('Win')\n",
    "\n",
    "# Mostra il grafico\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ci-fLJ3OwGs-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
